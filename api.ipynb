{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725d124e-41e4-46e3-b2a1-634fff176e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask import request, jsonify\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442c6390-eb1d-4477-9286-36af054c7214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "#load models\n",
    "model = torch.load('bert_opossum_best_0.6753.pt')\n",
    "tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531f8c36-63d6-4811-a210-44434e41c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize, predict, text preprocessing functions\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        return_token_type_ids=False,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "        )\n",
    "\n",
    "def predict(df):\n",
    "    batch = pd.DataFrame.from_records(df['text'].apply(tokenize_text).values)\n",
    "    input_ids = [a.numpy()[0] for a in batch.iloc[:,1].values]\n",
    "    input_ids = torch.from_numpy(np.array([a for a in input_ids],dtype=int)).to(device)\n",
    "    attention_mask =  [a.numpy()[0] for a in batch.iloc[:,0].values]\n",
    "    attention_mask = torch.from_numpy(np.array([a for a in attention_mask],dtype=int)).to(device)\n",
    "    \n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "    )\n",
    "    \n",
    "    prediction = outputs.logits\n",
    "\n",
    "    prob = nnf.softmax(prediction , dim=1)\n",
    "\n",
    "    top_p, top_class = prob.topk(1, dim = 1)\n",
    "    \n",
    "    df['score'] = (top_p.cpu().detach().numpy().reshape(-1)*100).astype(int)\n",
    "    df['type']=top_class.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "russian_stopwords.append('российской')\n",
    "russian_stopwords.append('федерации')\n",
    "russian_stopwords.append('федерального')\n",
    "russian_stopwords.append('настоящих')\n",
    "russian_stopwords.append('соответствии')\n",
    "russian_stopwords.append('также')\n",
    "russian_stopwords.append('рф')\n",
    "russian_stopwords.append('ред')\n",
    "\n",
    "russian_stopwords.append('субсидии')\n",
    "russian_stopwords.append('предоставления')\n",
    "\n",
    "\n",
    "def lowercase(text):\n",
    "    return str(text).lower()\n",
    "\n",
    "def clean_symb(text):\n",
    "    return re.sub(r'[^\\w]', ' ', text)\n",
    "\n",
    "def clear_token(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def clean_stopwords(token):\n",
    "    return ' '.join([i for i in token.split(' ') if i not in russian_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074dd494-2671-4950-a728-d83b18203021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test json data\n",
    "\n",
    "json = {'1': '1. {2} Настоящие Правила устанавливают цели, условия и порядок предоставления субсидии из федерального бюджета Фонду \"Центр стратегических разработок\" (далее - Фонд) в целях оценки эффектов от реализации инвестиционных проектов в сфере транспорта в рамках государственной программы Российской Федерации \"Экономическое развитие и инновационная экономика\" (далее - субсидия). {2}', '2': '2. {3} Предоставление субсидии осуществляется в пределах лимитов бюджетных обязательств, доведенных в установленном порядке до Министерства экономического развития Российской Федерации как получателя средств федерального бюджета на цели, указанные в пункте 1 настоящих Правил. {3}', '3': '3. {24} Субсидия предоставляется на основании соглашения о предоставлении субсидии, заключаемого между Министерством экономического развития Российской Федерации и Фондом (далее - соглашение о предоставлении субсидии). {24}', '4': '4. {24} Соглашение о предоставлении субсидии содержит в том числе: {24}', '5': '5. {24} Соглашение о предоставлении субсидии и дополнительные соглашения к нему, предусматривающие внесение изменений, или дополнительное соглашение о расторжении соглашения о предоставлении субсидии заключаются в государственной интегрированной информационной системе управления общественными финансами \"Электронный бюджет\" в соответствии с типовой формой, установленной Министерством финансов Российской Федерации.{24}', '6': '6. {4} Субсидия предоставляется на финансовое обеспечение затрат, связанных с достижением целей, указанных в пункте 1 настоящих Правил, в том числе понесенных Фондом в текущем финансовом году до заключения соглашения о предоставлении субсидии (при наличии документов, подтверждающих фактически произведенные затраты), в размере, определяемом по формуле: {4}', '7': '7. {22} Размер субсидии (Рсуб) определяется в пределах лимитов бюджетных обязательств, утвержденных и доведенных в установленном порядке до Министерства экономического развития Российской Федерации как получателя средств федерального бюджета на цели, указанные в пункте 1 настоящих Правил. {22}', '8': '8. {11} Фонд по состоянию на 1-е число месяца, предшествующего месяцу, в котором заключается соглашение о предоставлении субсидии, должен соответствовать следующим требованиям: {11}', '9': '9. {19} Для заключения соглашения о предоставлении субсидии Фонд представляет в Министерство экономического развития Российской Федерации документы, подписанные руководителем Фонда (иным уполномоченным лицом), подтверждающие соответствие Фонда каждому из требований, предусмотренных пунктом 8 настоящих Правил. {19}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c8a1bc-4863-4256-b721-10917765b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': [2, 99], '2': [4, 46], '3': [24, 90], '4': [24, 99], '5': [24, 96], '6': [4, 91], '7': [22, 99], '8': [11, 86], '9': [19, 99]}\n"
     ]
    }
   ],
   "source": [
    "#test prediction from data\n",
    "\n",
    "content =json\n",
    "df = pd.DataFrame.from_dict(content,orient='index',columns=['text'])\n",
    "df['text'] = df.text.apply(lowercase)\n",
    "df['text'] = df.text.apply(clean_symb)\n",
    "df['text'] = df.text.apply(lambda x:''.join([a for a in x if not a.isdigit()]))\n",
    "df['text'] = df.text.apply(lambda x:' '.join([a for a in x.split(' ') if len(a)>1]))\n",
    "df['text'] = df.text.apply(clean_stopwords)\n",
    "predict(df)\n",
    "df['type']+=1\n",
    "\n",
    "print(df[['type','score']].T.to_dict(orient='list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4cefb8-d8be-440c-b428-a2706446e82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#flask api\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/api', methods=['GET', 'POST'])\n",
    "def info():\n",
    "    content = request.json\n",
    "    df = pd.DataFrame.from_dict(content,orient='index',columns=['text'])\n",
    "    print(df.shape)\n",
    "    df['text'] = df.text.apply(lowercase)\n",
    "    df['text'] = df.text.apply(clean_symb)\n",
    "    df['text'] = df.text.apply(lambda x:''.join([a for a in x if not a.isdigit()]))\n",
    "    df['text'] = df.text.apply(lambda x:' '.join([a for a in x.split(' ') if len(a)>1]))\n",
    "    df['text'] = df.text.apply(clean_stopwords)\n",
    "    if df.shape[0]>0:\n",
    "        predict(df)\n",
    "        df['type']+=1\n",
    "\n",
    "    return df[['type','score']].T.to_dict(orient='list')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='172.19.0.178',port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack",
   "language": "python",
   "name": "hack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
